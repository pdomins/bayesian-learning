{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjVxSbp-YsE"
      },
      "source": [
        "# Clasificador Naive Bayes de noticias argentinas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PP1tQgGbXYZ"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pdomins/bayesian-learning/blob/master/ej2_bayes_news.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exi3zUTTOjeO"
      },
      "source": [
        "El objetivo de este ejercicio es implementar un clasificador de texto utilizando el **clasificador ingenuo de Bayes** sobre el\n",
        "conjunto de datos *”Noticias Argentinas”* para clasificar cada noticia según su tipo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instalaciones previas necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m pip install nltk       # for stopwords\n",
        "!python -m pip install spacy      # for tokenization\n",
        "!python -m pip install openpyxl   # for file reading\n",
        "!python -m spacy download es_core_news_md   # for lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcDtfWs-k-r"
      },
      "source": [
        "Librerías utilizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CBJtDroUVQfh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import nltk     # for stopwords\n",
        "import spacy    # for tokenization and lemmatization\n",
        "import re       # for regular expressions\n",
        "\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c2pgfET-eGO"
      },
      "source": [
        "## Análisis del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2nGoBuY_XIs"
      },
      "source": [
        "En principio contamos con 164690 tuplas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Pp3MXdG8vCZe",
        "outputId": "5b38bcc4-bdb6-414d-9cb7-ae1362209547"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha</th>\n",
              "      <th>titular</th>\n",
              "      <th>fuente</th>\n",
              "      <th>categoria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14/11/2018 09:08</td>\n",
              "      <td>Trabajadores del Buenos Aires Design cortan la...</td>\n",
              "      <td>Infobae.com</td>\n",
              "      <td>Nacional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13/11/2018 14:14</td>\n",
              "      <td>La boda del gobernador Gerardo Morales: tapas ...</td>\n",
              "      <td>Clarín.com</td>\n",
              "      <td>Nacional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14/11/2018 10:08</td>\n",
              "      <td>Cumbre del G20: qué calles estarán cortadas y ...</td>\n",
              "      <td>iprofesional.com</td>\n",
              "      <td>Nacional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14/11/2018 02:02</td>\n",
              "      <td>Una fractura que confirma la candidatura de Cr...</td>\n",
              "      <td>LA NACION (Argentina.)</td>\n",
              "      <td>Nacional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14/11/2018 09:03</td>\n",
              "      <td>Infierno grande: ola de divorcios en un pueblo...</td>\n",
              "      <td>Diario El Día</td>\n",
              "      <td>Nacional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164685</th>\n",
              "      <td>19/8/2019 09:13</td>\n",
              "      <td>¡Que lo vengan a Berlín!</td>\n",
              "      <td>Olé</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164686</th>\n",
              "      <td>20/8/2019 09:56</td>\n",
              "      <td>Con datos de la NASA, identifican 10 mil millo...</td>\n",
              "      <td>LaRepública.pe</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164687</th>\n",
              "      <td>19/8/2019 16:20</td>\n",
              "      <td>3 enfermedades de transmisión sexual que puede...</td>\n",
              "      <td>La 100</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164688</th>\n",
              "      <td>19/8/2019 20:12</td>\n",
              "      <td>Hallan evidencia de que la meditación plena ay...</td>\n",
              "      <td>Clarín</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164689</th>\n",
              "      <td>19/8/2019 07:46</td>\n",
              "      <td>Científicos argentinos descubren una nueva for...</td>\n",
              "      <td>Elonce.com</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>164690 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   fecha                                            titular  \\\n",
              "0       14/11/2018 09:08  Trabajadores del Buenos Aires Design cortan la...   \n",
              "1       13/11/2018 14:14  La boda del gobernador Gerardo Morales: tapas ...   \n",
              "2       14/11/2018 10:08  Cumbre del G20: qué calles estarán cortadas y ...   \n",
              "3       14/11/2018 02:02  Una fractura que confirma la candidatura de Cr...   \n",
              "4       14/11/2018 09:03  Infierno grande: ola de divorcios en un pueblo...   \n",
              "...                  ...                                                ...   \n",
              "164685   19/8/2019 09:13                           ¡Que lo vengan a Berlín!   \n",
              "164686   20/8/2019 09:56  Con datos de la NASA, identifican 10 mil millo...   \n",
              "164687   19/8/2019 16:20  3 enfermedades de transmisión sexual que puede...   \n",
              "164688   19/8/2019 20:12  Hallan evidencia de que la meditación plena ay...   \n",
              "164689   19/8/2019 07:46  Científicos argentinos descubren una nueva for...   \n",
              "\n",
              "                        fuente            categoria  \n",
              "0                  Infobae.com             Nacional  \n",
              "1                   Clarín.com             Nacional  \n",
              "2             iprofesional.com             Nacional  \n",
              "3       LA NACION (Argentina.)             Nacional  \n",
              "4                Diario El Día             Nacional  \n",
              "...                        ...                  ...  \n",
              "164685                     Olé  Noticias destacadas  \n",
              "164686          LaRepública.pe  Noticias destacadas  \n",
              "164687                  La 100  Noticias destacadas  \n",
              "164688                  Clarín  Noticias destacadas  \n",
              "164689              Elonce.com  Noticias destacadas  \n",
              "\n",
              "[164690 rows x 4 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/noticias_argentinas_clean_2.csv\", delimiter=\";\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eimjuDt0_eU1"
      },
      "source": [
        "Al enumerar las categorías nos encontramos con el valor NaN, indicando que hay tuplas sin especificar su categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC_NyhA6B_8t",
        "outputId": "7ea6b658-3848-4dfd-fd2c-1d677b8d878d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Nacional', 'Destacadas', 'Deportes', 'Salud',\n",
              "       'Ciencia y Tecnologia', 'Entretenimiento', 'Economia',\n",
              "       'Internacional', nan, 'Noticias destacadas'], dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['categoria'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkhm04oB_z4o"
      },
      "source": [
        "Al contar los valores por cada una:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJTkTwY5AgqI",
        "outputId": "5613f88e-79bc-4d55-fb8a-6e08dba32458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categoria\n",
            "Ciencia y Tecnologia      3856\n",
            "Deportes                  3855\n",
            "Destacadas                3859\n",
            "Economia                  3850\n",
            "Entretenimiento           3850\n",
            "Internacional             3850\n",
            "Nacional                  3860\n",
            "Noticias destacadas     133819\n",
            "Salud                     3840\n",
            "Name: titular, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('categoria')['titular'].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTunm_q86cd3"
      },
      "source": [
        "Además, al observar el dataset podemos ver que existen tuplas que se encuentran repetidas. Teniendo esto en cuenta, contamos nuevamente las noticias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BkP2SJuyHMG",
        "outputId": "fa81f3f3-379a-4970-f75a-7fb049f0b844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categoria\n",
            "Ciencia y Tecnologia      889\n",
            "Deportes                 1803\n",
            "Destacadas               2195\n",
            "Economia                 1186\n",
            "Entretenimiento          1506\n",
            "Internacional            1739\n",
            "Nacional                 1582\n",
            "Noticias destacadas     39456\n",
            "Salud                     797\n",
            "Name: titular, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('categoria')['titular'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La categoría \"Noticias destacadas\" tiene una cantidad considerablemente mayor de titulares que el resto. Además, es una categoría general que contempla a noticias de todo tipo. En ejecuciones anteriores esto demostró un error muy grande al estimar. Como también afecta en la performance, vamos a desestimar todas las noticias que caigan dentro de esta categoría... por ahora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categoria\n",
            "Ciencia y Tecnologia    3856\n",
            "Deportes                3855\n",
            "Destacadas              3859\n",
            "Economia                3850\n",
            "Entretenimiento         3850\n",
            "Internacional           3850\n",
            "Nacional                3860\n",
            "Salud                   3840\n",
            "Name: titular, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_filtered = df[df['categoria'] != 'Noticias destacadas']\n",
        "print(df_filtered.groupby('categoria')['titular'].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RfoY7v-Qer"
      },
      "source": [
        "## Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdGbZ0LkZM9F"
      },
      "source": [
        "Vamos a expresar los títulos como un array conformado por sus palabras relevantes lematizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPlQ9HN0nuxt",
        "outputId": "fe614780-36c9-441f-fadb-f0997e19ba6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "# tokenization and lemmatization\n",
        "nlp = spacy.load(\"es_core_news_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_numbers_and_symbols(input_string):\n",
        "    pattern = r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ\\s]'\n",
        "    cleaned_string = re.sub(pattern, '', input_string)\n",
        "    return cleaned_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_7c3NAK5mQDZ"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(title_string : str):\n",
        "\n",
        "  # removing unnecesary symbols and tokenization\n",
        "  title = nlp(remove_numbers_and_symbols(title_string))\n",
        "\n",
        "  lemmas = []\n",
        "\n",
        "  for tok in title:\n",
        "    word = tok.lemma_.lower()\n",
        "    if word not in stop_words:\n",
        "      lemmas.append(word)\n",
        "\n",
        "  return lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQCxh-xMrNLX"
      },
      "source": [
        "## Armado de vocabulario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4eQFxQQacr-"
      },
      "source": [
        "Para empezar creamos un diccionario con todas las palabras utilizadas en los titulares para cada categoría, evitando repetidos en cada set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_7NcVtZVDon",
        "outputId": "a9136a07-ac12-4756-c186-f63e301bc766"
      },
      "outputs": [],
      "source": [
        "def get_categories(df : pd.DataFrame):\n",
        "    return df.dropna(subset=['categoria'])['categoria'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JdBDC5qyRNn2"
      },
      "outputs": [],
      "source": [
        "def get_vocab(df : pd.DataFrame, categories: list):\n",
        "\n",
        "  vocab = {}\n",
        "\n",
        "  for category in categories:\n",
        "\n",
        "    # set of words used in the current category\n",
        "    cat_vocab = set()\n",
        "\n",
        "    # subset of training data of the current category\n",
        "    cat_train_df = df[df['categoria'] == category]\n",
        "\n",
        "    for title in cat_train_df['titular']:\n",
        "      cat_vocab.update(title)\n",
        "\n",
        "    vocab[category] = list(cat_vocab)\n",
        "  \n",
        "  return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GswrDveSeiUE"
      },
      "source": [
        "## Cálculo de frecuencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpdShFciuFIZ"
      },
      "source": [
        "Iteramos los titulares dentro de cada categoría y calculamos la frecuencia de aparición de las palabras dentro de cada categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BTqOhoyQaoq9"
      },
      "outputs": [],
      "source": [
        "def get_frequencies(df : pd.DataFrame, categories : list, vocab : dict):\n",
        "\n",
        "  vocab_freq = {}\n",
        "  laplace_vocab_freq = {}\n",
        "  titles_by_cat = {}\n",
        "\n",
        "  for cat_idx, category in enumerate(categories):\n",
        "\n",
        "    # all the words used the in current category\n",
        "    word_list = vocab[categories[cat_idx]]\n",
        "\n",
        "    # dict with the frequencies of every word in the current category\n",
        "    words_freq = { key: 0 for key in word_list }\n",
        "    words_laplace_freq = { key: 0 for key in word_list }\n",
        "\n",
        "    # training data subset of the current category\n",
        "    cat_train_df = df[df['categoria'] == category]\n",
        "\n",
        "    # amount of titles in the current category\n",
        "    cat_title_count = len(cat_train_df['titular'])\n",
        "    titles_by_cat[category] = cat_title_count\n",
        "\n",
        "    for word in word_list:\n",
        "      for title in cat_train_df['titular']:\n",
        "        if word in title:\n",
        "          words_freq[word] += (1 / cat_title_count)\n",
        "          words_laplace_freq[word] += (1 / (cat_title_count+len(categories)))\n",
        "      words_laplace_freq[word] += (1 / (cat_title_count+len(categories)))\n",
        "\n",
        "    vocab_freq[category] = words_freq\n",
        "    laplace_vocab_freq[category] = words_laplace_freq\n",
        "\n",
        "  return vocab_freq, laplace_vocab_freq, titles_by_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU5U3yzsj6CF"
      },
      "source": [
        "## Cálculo de probabilidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibh1KbtJkCKs"
      },
      "source": [
        "Primero calculamos la probabilidad de que un titular pertenezca a cierta categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmc7pkItpNZj",
        "outputId": "1bb9589a-70d2-41a9-b7b0-c9af49010b9c"
      },
      "outputs": [],
      "source": [
        "def p_cat(categories : list, titles_by_cat : dict):\n",
        "\n",
        "  title_count = sum(titles_by_cat.values())\n",
        "  p_cat = { key: 0 for key in categories }\n",
        "\n",
        "  for category in categories:\n",
        "    p_cat[category] = titles_by_cat[category] / title_count\n",
        "\n",
        "  return p_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAGAsE5BkSuV"
      },
      "source": [
        "Con esta información y con las frecuencias guardadas en la sección anterior podemos calcular **P(A|categoria)**, es decir, la probabilidad de ocurrencia de un conjunto de palabras dada cierta categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bciZnDagksGd"
      },
      "outputs": [],
      "source": [
        "def p_a_cat(conj_a : list, cat_vocab_freq : dict):\n",
        "  prob = 1\n",
        "  for word in conj_a:\n",
        "    prob *= cat_vocab_freq.get(word, 0)\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VNPimmG_LhHv"
      },
      "outputs": [],
      "source": [
        "def p_a_cat_laplace(conj_a : list, cat_laplace_vocab_freq : dict, total_titles_cat : int, k_classes : int):\n",
        "  prob = 1\n",
        "  for word in conj_a:\n",
        "    freq = cat_laplace_vocab_freq.get(word, 0)\n",
        "    if freq > 0:\n",
        "      prob *= freq\n",
        "    else:\n",
        "      prob *= (1 / (total_titles_cat+k_classes))\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-lL8kdH15DW"
      },
      "source": [
        "Luego obtenemos **P(A)**, la probabilidad de ocurrencia de un conjunto de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f90_6XJu14hL"
      },
      "outputs": [],
      "source": [
        "def p_a(conj_a : list, categories : list, prob_cats : dict, vocab_freq : dict, titles_by_cat : dict, laplace_smoothing : bool = False, laplace_vocab_freq : dict = None):\n",
        "  prob = 0\n",
        "  for category in categories:\n",
        "    prob_a_cat = 0\n",
        "    if laplace_smoothing:\n",
        "      prob_a_cat = p_a_cat_laplace(conj_a, laplace_vocab_freq[category], titles_by_cat[category], len(categories))\n",
        "    else:\n",
        "      prob_a_cat = p_a_cat(conj_a, vocab_freq[category])\n",
        "    prob += (prob_a_cat * prob_cats[category])\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ0yMI_-xX66"
      },
      "source": [
        "Finalmente podemos calcular **P(categoria|A)**, la probabilidad de que un titular pertenezca a cierta categoría dado su conjunto de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m5TXmnx343P4"
      },
      "outputs": [],
      "source": [
        "def p_cat_a(prob_a_cat : int, prob_cat : int, prob_a : int):\n",
        "  return prob_a_cat * prob_cat / prob_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IQYxgMR5jm1"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGu297RC5mnl"
      },
      "source": [
        "Calculamos las probabilidades P(categoria|A) para cada categoría y nos quedamos con la de mayor valor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive_bayes(conj_a : list, categories : list, vocab_freq : dict, titles_by_cat : dict, prob_cats : dict, laplace_smoothing : bool = False, laplace_vocab_freq : dict = None):\n",
        "\n",
        "  p_cats_a = {}\n",
        "  prob_a = p_a(conj_a, categories, prob_cats, vocab_freq, titles_by_cat, laplace_smoothing, laplace_vocab_freq)\n",
        "\n",
        "  for category in categories:\n",
        "\n",
        "    prob_a_cat = 0\n",
        "    if laplace_smoothing:\n",
        "      prob_a_cat = p_a_cat_laplace(conj_a, laplace_vocab_freq[category], titles_by_cat[category], len(categories))\n",
        "    else:\n",
        "      prob_a_cat = p_a_cat(conj_a, vocab_freq[category])\n",
        "\n",
        "    p_cats_a[category] = p_cat_a(prob_a_cat, prob_cats[category], prob_a)\n",
        "  \n",
        "  return max(p_cats_a, key = lambda k: p_cats_a[k]), p_cats_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probando el clasificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizamos el método K-Fold para futura cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_split import k_fold_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a crear dos conjuntos, uno de entrenamiento y otro de testeo, por lo que nos queda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15435.5, 15435.5)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = 2\n",
        "\n",
        "test_size = df_filtered.shape[0] / k\n",
        "(test_size * (k-1), test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = k_fold_split(df_filtered, k)\n",
        "train_df['titular'] = train_df['titular'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "categories = get_categories(train_df)\n",
        "vocab = get_vocab(train_df, categories)\n",
        "vocab_freq, laplace_vocab_freq, titles_by_cat = get_frequencies(train_df, categories, vocab)\n",
        "prob_cats = p_cat(categories, titles_by_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akIjEVIYGWQg",
        "outputId": "d30de8e5-9e38-4d01-d1ec-557e6a047890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P ( cat = 'Ciencia y Tecnologia' | A ) = 0.008209896391207018\n",
            "P ( cat = 'Entretenimiento' | A ) = 0.016681756880088248\n",
            "P ( cat = 'Destacadas' | A ) = 0.025061328785612423\n",
            "P ( cat = 'Economia' | A ) = 0.008152082121581639\n",
            "P ( cat = 'Salud' | A ) = 0.008440791720952788\n",
            "P ( cat = 'Deportes' | A ) = 0.8913898717544733\n",
            "P ( cat = 'Internacional' | A ) = 0.008353776261870807\n",
            "P ( cat = 'Nacional' | A ) = 0.03371049608421387\n",
            "\n",
            "Selected class: Deportes\n"
          ]
        }
      ],
      "source": [
        "selected_class, p_cats_a = naive_bayes([\"messi\", \"pelota\"], categories, vocab_freq, titles_by_cat, prob_cats, True, laplace_vocab_freq)\n",
        "\n",
        "for category in p_cats_a.keys():\n",
        "    print(f\"P ( cat = '{category}' | A ) = {p_cats_a[category]}\")\n",
        "\n",
        "print(f\"\\nSelected class: {selected_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(test_serie : pd.Series):\n",
        "    title = preprocess_text(test_serie['titular'])\n",
        "    selected_class, _ = naive_bayes(title, categories, vocab_freq, titles_by_cat, prob_cats, True, laplace_vocab_freq)\n",
        "    return selected_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from error_functions import compute_classification_error\n",
        "from df_utils        import get_column_value_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df_label_dict = get_column_value_dict(test_df, \"categoria\")\n",
        "error_cases = compute_classification_error(test_df, test_df_label_dict, lambda s : predict(s))\n",
        "total_cases = test_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error en 2680 de 15435 titulares (17.36%)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Error en {error_cases} de {total_cases} titulares ({round(error_cases/total_cases*100, 2)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## División óptima del conjunto de textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Próximamente"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
