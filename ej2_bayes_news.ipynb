{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjVxSbp-YsE"
      },
      "source": [
        "# Clasificador Naive Bayes de noticias argentinas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PP1tQgGbXYZ"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pdomins/bayesian-learning/blob/master/ej2_bayes_news.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exi3zUTTOjeO"
      },
      "source": [
        "El objetivo de este ejercicio es implementar un clasificador de texto utilizando el **clasificador ingenuo de Bayes** sobre el\n",
        "conjunto de datos *”Noticias Argentinas”* para clasificar cada noticia según su tipo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instalaciones previas necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m pip install nltk       # for stopwords\n",
        "!python -m pip install spacy      # for tokenization\n",
        "!python -m pip install openpyxl   # for file reading\n",
        "!python -m spacy download es_core_news_md   # for lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcDtfWs-k-r"
      },
      "source": [
        "Librerías utilizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CBJtDroUVQfh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c2pgfET-eGO"
      },
      "source": [
        "## Análisis del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2nGoBuY_XIs"
      },
      "source": [
        "En principio contamos con 164690 tuplas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Pp3MXdG8vCZe",
        "outputId": "5b38bcc4-bdb6-414d-9cb7-ae1362209547"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha</th>\n",
              "      <th>titular</th>\n",
              "      <th>fuente</th>\n",
              "      <th>categoria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-12-13 15:49:06</td>\n",
              "      <td>Se van los Melli</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-12-26 21:21:41</td>\n",
              "      <td>Cantos racistas en el Calcio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-12-26 21:21:41</td>\n",
              "      <td>Cantos racistas en el Calcio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-13 16:35:30</td>\n",
              "      <td>Los que viajan a Uruguay son...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-13 16:35:30</td>\n",
              "      <td>Los que viajan a Uruguay son...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noticias destacadas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164685</th>\n",
              "      <td>2018-11-26 11:34:11</td>\n",
              "      <td>River Boca: el Gobierno nacional pide â€œinves...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164686</th>\n",
              "      <td>2018-11-26 11:34:11</td>\n",
              "      <td>River Boca: el Gobierno nacional pide â€œinves...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164687</th>\n",
              "      <td>2018-11-24 22:25:24</td>\n",
              "      <td>Se postergó San Lorenzo Huracán: el resto de l...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164688</th>\n",
              "      <td>2018-11-24 22:25:24</td>\n",
              "      <td>Se postergó San Lorenzo Huracán: el resto de l...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164689</th>\n",
              "      <td>2018-11-28 12:10:27</td>\n",
              "      <td>Talleres Racing, por la Superliga: formaciones...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>164690 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     fecha                                            titular  \\\n",
              "0      2018-12-13 15:49:06                                   Se van los Melli   \n",
              "1      2018-12-26 21:21:41                       Cantos racistas en el Calcio   \n",
              "2      2018-12-26 21:21:41                       Cantos racistas en el Calcio   \n",
              "3      2019-01-13 16:35:30                    Los que viajan a Uruguay son...   \n",
              "4      2019-01-13 16:35:30                    Los que viajan a Uruguay son...   \n",
              "...                    ...                                                ...   \n",
              "164685 2018-11-26 11:34:11  River Boca: el Gobierno nacional pide â€œinves...   \n",
              "164686 2018-11-26 11:34:11  River Boca: el Gobierno nacional pide â€œinves...   \n",
              "164687 2018-11-24 22:25:24  Se postergó San Lorenzo Huracán: el resto de l...   \n",
              "164688 2018-11-24 22:25:24  Se postergó San Lorenzo Huracán: el resto de l...   \n",
              "164689 2018-11-28 12:10:27  Talleres Racing, por la Superliga: formaciones...   \n",
              "\n",
              "       fuente            categoria  \n",
              "0         NaN  Noticias destacadas  \n",
              "1         NaN  Noticias destacadas  \n",
              "2         NaN  Noticias destacadas  \n",
              "3         NaN  Noticias destacadas  \n",
              "4         NaN  Noticias destacadas  \n",
              "...       ...                  ...  \n",
              "164685    NaN                  NaN  \n",
              "164686    NaN                  NaN  \n",
              "164687    NaN                  NaN  \n",
              "164688    NaN                  NaN  \n",
              "164689    NaN                  NaN  \n",
              "\n",
              "[164690 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel(\"data/Noticias_argentinas_clean.xlsx\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vl8x84lA6-B",
        "outputId": "ae9b6992-5ea9-4a67-cdc3-7739f7d08bba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(958,)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['fuente'].unique().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eimjuDt0_eU1"
      },
      "source": [
        "Al enumerar las categorías nos encontramos con el valor NaN, indicando que hay tuplas sin especificar su categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC_NyhA6B_8t",
        "outputId": "7ea6b658-3848-4dfd-fd2c-1d677b8d878d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Noticias destacadas', 'Ciencia y Tecnologia', nan, 'Deportes',\n",
              "       'Entretenimiento', 'Destacadas', 'Actualidad', 'Crítica'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['categoria'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkhm04oB_z4o"
      },
      "source": [
        "Al contar los valores por cada una:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJTkTwY5AgqI",
        "outputId": "5613f88e-79bc-4d55-fb8a-6e08dba32458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categoria\n",
            "Actualidad                   1\n",
            "Ciencia y Tecnologia      2966\n",
            "Crítica                      4\n",
            "Deportes                  2969\n",
            "Destacadas                2971\n",
            "Entretenimiento           2961\n",
            "Noticias destacadas     133864\n",
            "Name: titular, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('categoria')['titular'].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTunm_q86cd3"
      },
      "source": [
        "Además, al observar el dataset más arriba, podemos ver que existen tuplas que se encuentran repetidas. Teniendo esto en cuenta, contamos nuevamente las noticias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BkP2SJuyHMG",
        "outputId": "fa81f3f3-379a-4970-f75a-7fb049f0b844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categoria\n",
            "Actualidad                  1\n",
            "Ciencia y Tecnologia      710\n",
            "Crítica                     1\n",
            "Deportes                 1402\n",
            "Destacadas               1731\n",
            "Entretenimiento          1199\n",
            "Noticias destacadas     39491\n",
            "Name: titular, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('categoria')['titular'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RfoY7v-Qer"
      },
      "source": [
        "## Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdGbZ0LkZM9F"
      },
      "source": [
        "Vamos a expresar los títulos como un array conformado por sus palabras relevantes lematizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPlQ9HN0nuxt",
        "outputId": "fe614780-36c9-441f-fadb-f0997e19ba6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "# tokenization and lemmatization\n",
        "nlp = spacy.load(\"es_core_news_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_7c3NAK5mQDZ"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(title_string : str):\n",
        "\n",
        "  # removing unnecesary symbols and tokenization\n",
        "  title = nlp(title_string.strip('.,+-#:;¿?¡!\"\\''))\n",
        "\n",
        "  lemmas = []\n",
        "\n",
        "  for tok in title:\n",
        "    word = tok.lemma_.lower()\n",
        "    if word not in stop_words:\n",
        "      lemmas.append(word)\n",
        "\n",
        "  return lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQCxh-xMrNLX"
      },
      "source": [
        "## Armado de vocabulario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4eQFxQQacr-"
      },
      "source": [
        "Para empezar creamos un diccionario con todas las palabras utilizadas en los titulares para cada categoría, evitando repetidos en cada set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_7NcVtZVDon",
        "outputId": "a9136a07-ac12-4756-c186-f63e301bc766"
      },
      "outputs": [],
      "source": [
        "def get_categories(df : pd.DataFrame):\n",
        "    return df.dropna(subset=['categoria'])['categoria'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JdBDC5qyRNn2"
      },
      "outputs": [],
      "source": [
        "def get_vocab(df : pd.DataFrame, categories: list):\n",
        "\n",
        "  vocab = {}\n",
        "\n",
        "  for category in categories:\n",
        "\n",
        "    # set of words used in the current category\n",
        "    cat_vocab = set()\n",
        "\n",
        "    # subset of training data of the current category\n",
        "    cat_train_df = df[df['categoria'] == category]\n",
        "\n",
        "    for title in cat_train_df['titular']:\n",
        "      cat_vocab.update(title)\n",
        "\n",
        "    vocab[category] = list(cat_vocab)\n",
        "  \n",
        "  return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GswrDveSeiUE"
      },
      "source": [
        "## Cálculo de frecuencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpdShFciuFIZ"
      },
      "source": [
        "Iteramos los titulares dentro de cada categoría y calculamos la frecuencia de aparición de las palabras dentro de cada categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BTqOhoyQaoq9"
      },
      "outputs": [],
      "source": [
        "def get_frequencies(df : pd.DataFrame, categories : list, vocab : dict):\n",
        "\n",
        "  vocab_freq = {}\n",
        "  laplace_vocab_freq = {}\n",
        "  titles_by_cat = {}\n",
        "\n",
        "  for cat_idx, category in enumerate(categories):\n",
        "\n",
        "    # all the words used the in current category\n",
        "    word_list = vocab[categories[cat_idx]]\n",
        "\n",
        "    # dict with the frequencies of every word in the current category\n",
        "    words_freq = { key: 0 for key in word_list }\n",
        "    words_laplace_freq = { key: 0 for key in word_list }\n",
        "\n",
        "    # training data subset of the current category\n",
        "    cat_train_df = df[df['categoria'] == category]\n",
        "\n",
        "    # amount of titles in the current category\n",
        "    cat_title_count = len(cat_train_df['titular'])\n",
        "    titles_by_cat[category] = cat_title_count\n",
        "\n",
        "    for word in word_list:\n",
        "      for title in cat_train_df['titular']:\n",
        "        if word in title:\n",
        "          words_freq[word] += (1 / cat_title_count)\n",
        "          words_laplace_freq[word] += (1 / (cat_title_count+len(categories)))\n",
        "      words_laplace_freq[word] += (1 / (cat_title_count+len(categories)))\n",
        "\n",
        "    vocab_freq[category] = words_freq\n",
        "    laplace_vocab_freq[category] = words_laplace_freq\n",
        "\n",
        "  return vocab_freq, laplace_vocab_freq, titles_by_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU5U3yzsj6CF"
      },
      "source": [
        "## Cálculo de probabilidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibh1KbtJkCKs"
      },
      "source": [
        "Primero calculamos la probabilidad de que un titular pertenezca a cierta categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmc7pkItpNZj",
        "outputId": "1bb9589a-70d2-41a9-b7b0-c9af49010b9c"
      },
      "outputs": [],
      "source": [
        "def p_cat(categories : list, titles_by_cat : dict):\n",
        "\n",
        "  title_count = sum(titles_by_cat.values())\n",
        "  p_cat = { key: 0 for key in categories }\n",
        "\n",
        "  for category in categories:\n",
        "    p_cat[category] = titles_by_cat[category] / title_count\n",
        "\n",
        "  return p_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAGAsE5BkSuV"
      },
      "source": [
        "Con esta información y con las frecuencias guardadas en la sección anterior podemos calcular **P(A|categoria)**, es decir, la probabilidad de ocurrencia de un conjunto de palabras dada cierta categoría:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bciZnDagksGd"
      },
      "outputs": [],
      "source": [
        "def p_a_cat(conj_a : list, cat_vocab_freq : dict):\n",
        "  prob = 1\n",
        "  for word in conj_a:\n",
        "    prob *= cat_vocab_freq.get(word, 0)\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VNPimmG_LhHv"
      },
      "outputs": [],
      "source": [
        "def p_a_cat_laplace(conj_a : list, cat_laplace_vocab_freq : dict, total_titles_cat : int, k_classes : int):\n",
        "  prob = 1\n",
        "  for word in conj_a:\n",
        "    freq = cat_laplace_vocab_freq.get(word, 0)\n",
        "    if freq > 0:\n",
        "      prob *= freq\n",
        "    else:\n",
        "      prob *= (1 / (total_titles_cat+k_classes))\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-lL8kdH15DW"
      },
      "source": [
        "Luego obtenemos **P(A)**, la probabilidad de ocurrencia de un conjunto de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f90_6XJu14hL"
      },
      "outputs": [],
      "source": [
        "def p_a(conj_a : list, categories : list, prob_cats : dict, vocab_freq : dict, titles_by_cat : dict, laplace_smoothing : bool = False, laplace_vocab_freq : dict = None):\n",
        "  prob = 0\n",
        "  for category in categories:\n",
        "    prob_a_cat = 0\n",
        "    if laplace_smoothing:\n",
        "      prob_a_cat = p_a_cat_laplace(conj_a, laplace_vocab_freq[category], titles_by_cat[category], len(categories))\n",
        "    else:\n",
        "      prob_a_cat = p_a_cat(conj_a, vocab_freq[category])\n",
        "    prob += (prob_a_cat * prob_cats[category])\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ0yMI_-xX66"
      },
      "source": [
        "Finalmente podemos calcular **P(categoria|A)**, la probabilidad de que un titular pertenezca a cierta categoría dado su conjunto de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m5TXmnx343P4"
      },
      "outputs": [],
      "source": [
        "def p_cat_a(prob_a_cat : int, prob_cat : int, prob_a : int):\n",
        "  return prob_a_cat * prob_cat / prob_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IQYxgMR5jm1"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGu297RC5mnl"
      },
      "source": [
        "Calculamos las probabilidades P(categoria|A) para cada categoría y nos quedamos con la de mayor valor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive_bayes(conj_a : list, categories : list, vocab_freq : dict, titles_by_cat : dict, prob_cats : dict, laplace_smoothing : bool = False, laplace_vocab_freq : dict = None):\n",
        "\n",
        "  p_cats_a = {}\n",
        "  prob_a = p_a(conj_a, categories, prob_cats, vocab_freq, titles_by_cat, laplace_smoothing, laplace_vocab_freq)\n",
        "\n",
        "  for category in categories:\n",
        "\n",
        "    prob_a_cat = 0\n",
        "    if laplace_smoothing:\n",
        "      prob_a_cat = p_a_cat_laplace(conj_a, laplace_vocab_freq[category], titles_by_cat[category], len(categories))\n",
        "    else:\n",
        "      prob_a_cat = p_a_cat(conj_a, vocab_freq[category])\n",
        "\n",
        "    p_cats_a[category] = p_cat_a(prob_a_cat, prob_cats[category], prob_a)\n",
        "  \n",
        "  return max(p_cats_a, key = lambda k: p_cats_a[k]), p_cats_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probando el clasificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizamos el método K-Fold para futura cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_split import k_fold_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a crear dos conjuntos, uno de entrenamiento y otro de testeo, por lo que nos queda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(82345.0, 82345.0)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = 2\n",
        "\n",
        "test_size = df.shape[0] / k\n",
        "(test_size * (k-1), test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = k_fold_split(df, k)\n",
        "train_df['titular'] = train_df['titular'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "categories = get_categories(train_df)\n",
        "vocab = get_vocab(train_df, categories)\n",
        "vocab_freq, laplace_vocab_freq, titles_by_cat = get_frequencies(train_df, categories, vocab)\n",
        "prob_cats = p_cat(categories, titles_by_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akIjEVIYGWQg",
        "outputId": "d30de8e5-9e38-4d01-d1ec-557e6a047890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P ( cat = 'Noticias destacadas' | A ) = 0.6113059800332089\n",
            "P ( cat = 'Ciencia y Tecnologia' | A ) = 0.0023863669028461256\n",
            "P ( cat = 'Entretenimiento' | A ) = 0.004614374008064825\n",
            "P ( cat = 'Deportes' | A ) = 0.2685002945138908\n",
            "P ( cat = 'Destacadas' | A ) = 0.0023735890696593293\n",
            "P ( cat = 'Actualidad' | A ) = 0.055409697736165\n",
            "P ( cat = 'Crítica' | A ) = 0.055409697736165\n",
            "\n",
            "Selected class: Noticias destacadas\n"
          ]
        }
      ],
      "source": [
        "selected_class, p_cats_a = naive_bayes([\"messi\", \"pelota\"], categories, vocab_freq, titles_by_cat, prob_cats, True, laplace_vocab_freq)\n",
        "\n",
        "for category in p_cats_a.keys():\n",
        "    print(f\"P ( cat = '{category}' | A ) = {p_cats_a[category]}\")\n",
        "\n",
        "print(f\"\\nSelected class: {selected_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(test_serie : pd.Series):\n",
        "    title = preprocess_text(test_serie['titular'])\n",
        "    selected_class, _ = naive_bayes(title, categories, vocab_freq, titles_by_cat, prob_cats, True, laplace_vocab_freq)\n",
        "    return selected_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from error_functions import compute_classification_error\n",
        "from df_utils        import get_column_value_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "81172"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df_label_dict = get_column_value_dict(test_df, \"categoria\")\n",
        "compute_classification_error(test_df, test_df_label_dict, lambda s : predict(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(82345, 4)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## División óptima del conjunto de textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Próximamente"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
